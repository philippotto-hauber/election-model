---
title: "Construct priors"
format: 
    html:
        page-layout: full
        embed-resources: true
        toc: true
        toc-location: left
        self-contained-math: true
        html-math-method: katex
---

This notebook constructs the **priors for the model estimation**. See `model_description.html`for details. Some of the priors are independent of the specific scenario being estimated, e.g. the innovations to the reverse random-walk $\boldsymbol{W}$; others depend on the scenario and the resulting *fundamental forecast*, e.g. the prior mean $m_{\mu_T}$ and variance $V_{\mu_T}$ on the (transformed) latent voting intentions on election day.

## To-dos

- ~~regularization of $\boldsymbol{\hat{W}}$~~ -> James-Stein type estimator from pkg `corpcor` 
- use historic polls to inform $\boldsymbol{\hat{W}}$
- simulate trajectories of $\mu_{1:T}$ for different values of $\kappa$ given $\boldsymbol{\hat{W}}$ -> **prior predictive distribution**
- simulate house effects by drawing from prior and using a sequence of polls from previous election as starting point -> **prior predictive distribution**
- differences in $V_{\mu_T}$ across scenarios
- ~~add forecasts from fundamental model~~

```{r}
#| output: false

# libraries
library(dplyr)

# source functions
names_functions = list.files(here::here("functions"))
for (f in names_functions)
    source(here::here("functions", f))
rm(f, names_functions)
```

## Preliminaries

Initialize empty list to store priors for different scenarios

```{r}
priors <- list() 
```

Load number of parties running in each state -> needed to set the prior on $\mu_T$
```{r}
n_parties_by_state <- load_n_parties_by_geography("state")
```

Load election results -> needed to estimate $\boldsymbol{W}$

```{r}
election_results <- load_election_vote_shares()
n_elections <- length(unique(election_results$year))
```

Calculate the dim names of $\mu_T$, i.e. the state and party that each entry refers to. These are also the dimnames of $\boldsymbol{W}$ and $V_{\mu_T}$. These serve as a cross-check that the priors are ordered in the same way as in the data preparation and estimation! 

```{r}
names_mmu_T <- c()
parties <- load_parties()
for (s in seq(1, length(n_parties_by_state))) {
    tmp <- paste0(names(n_parties_by_state)[s], "_")
    for (p in seq(1, n_parties_by_state[s] - 1)) {
        names_mmu_T <- c(names_mmu_T, paste0(tmp, parties[p]))        
    }
}
```

## Scenario-independent priors

### covariance matrix $\boldsymbol{W}$

To specify the "prior" on the innovations to the reverse random-walk, it is useful to decompose the covariance as 

$$
\boldsymbol{W} = \kappa \times \boldsymbol{\hat{W}}
$$

where $\boldsymbol{\hat{W}}$ is a correlation matrix and $\kappa$ a scale factor. Intuitively, $\boldsymbol{\hat{W}}$ accounts for the comovement of the changes in latent voting intentions across parties and states while $\kappa$ governs how large changes in voting intentions are!

#### Correlation matrix $\boldsymbol{\hat{W}}$

To calculate the correlation matrix I rely on two sources of information: 

- actual election results
- similarities in demographics across states

For the former I use all the available election results since 


> [...] although parties’ vote shares in each province oscillate from year to year—possibly for quantifiable reasons like the strength of the economy, and possibly for unquantifiable ones like the comparative appeal of their candidates or of their proposed policies—the baseline popularity of each party in each province is constant all the way from 1984 to 2024, as are the characteristics of each pollster. There is no equivalent in Dataland of, say, West Virginia in the United States shifting over time from a reliably Democratic-voting state to a reliably Republican-voting one, because there are no long-run time trends. As a result, when predicting elections in 2024, **you should treat historical results and polls from 1984 as being just as informative as those from 2023 are**. (background material on Dataland, my emphasis)


```{r}
# loop over elections
df_corr <- data.frame()
for (y in seq(min(election_results$year), max(election_results$year))){

    election_results %>% 
        filter(year == y) %>%
        select(state, region, cc, dgm, pdal, ssp) %>% 
        arrange(region, state) -> election_result

    # convert to log ratios
    result_lr <- election_result
    result_lr[, c("cc", "dgm", "pdal", "ssp")] <- NA

    for (i in seq(1, nrow(election_result))) {
        n_parties_i <- n_parties_by_state[election_result$state[i]]
        # return vote shares as vector -> not sure why drop = TRUE returns list!?
        tmp_voteshares <- unlist(election_result[i, c("cc", "dgm", "pdal", "ssp"), 
                                                 drop = TRUE])
        if (n_parties_i == 3)
            tmp_voteshares <- tmp_voteshares[1:3] 
        tmp_lr <- additive_log_ratio(tmp_voteshares)
        if (n_parties_i == 3)
            result_lr[i, c("cc", "dgm", "pdal")] <- tmp_lr
        else 
            result_lr[i, c("cc", "dgm", "pdal", "ssp")] <- tmp_lr
    }

    result_lr %>% 
        mutate(year = y) %>%
        tidyr::pivot_longer(cols = c("cc", "dgm", "pdal", "ssp"),
                            names_to = "party", 
                            values_to = "value") -> result_lr_long

    result_lr_long %>% 
        select(-region) %>% 
        filter(!is.na(value), value != 0) %>%
        tidyr::unite(col = "state_party", state, party) %>%
        tidyr::pivot_wider(names_from = state_party, values_from = value) -> df_corr_tmp

    df_corr <- rbind(df_corr, df_corr_tmp)
}

df_corr %>% 
    select(-year) %>% 
    as.matrix -> mat_results 

# check dims
if (!(nrow(mat_results) == n_elections & 
        ncol(mat_results) == sum(n_parties_by_state-1)))
    stop("Dimensions of matrix containing log ratio election results not correct. Abort!")

corr_mat <- cor(mat_results)
# James-Stein type shirnkage estimator
corr_mat_js <- corpcor::cor.shrink(mat_results)
```

Compare original and shrunk version of corr matrix

```{r}
corpcor::is.positive.definite(corr_mat)
corpcor::rank.condition(corr_mat)
MASS::mvrnorm(
    n = 1,
    mu = rep(0, nrow(corr_mat)),
    Sigma = corr_mat)
```

```{r}
corpcor::is.positive.definite(corr_mat_shrink)
corpcor::rank.condition(corr_mat_shrink)
MASS::mvrnorm(
    n = 1,
    mu = rep(0, nrow(corr_mat_shrink)),
    Sigma = corr_mat_shrink)
```

```{r}
heatmap(
    corr_mat, 
    Rowv = NA, 
    Colv = NA, 
    main = "original correlation matrix"
)
```

```{r}
heatmap(
    corr_mat_shrink,
    Rowv = NA, 
    Colv = NA,
    main = "shrunk correlation matrix")
```

Both matrices are PD and can be sampled from but shrunk matrix much better conditioned! 

#### Scale factor $\kappa$

#### Calculate $\boldsymbol{W}$ and store in list

For the time being, simply set $\boldsymbol{W}$ to a diagonal matrix: 

```{r}
W <- diag(0.01, nrow = sum(n_parties_by_state-1))
dimnames(W) <- list(names_mmu_T, names_mmu_T)
```

Store in list
```{r}
priors[["A"]][["W"]] <- 
    priors[["B"]][["W"]] <- 
    priors[["C"]][["W"]] <- 
    priors[["D"]][["W"]] <- 
    priors[["E"]][["W"]] <- W
```

### $\sigma^2_{\delta}$

```{r}
sig_ddelta <- sqrt(0.01) # specify in terms of standard deviation for Stan!
```

Store in list

```{r}
priors[["A"]][["sig_ddelta"]] <- 
    priors[["B"]][["sig_ddelta"]] <- 
    priors[["C"]][["sig_ddelta"]] <- 
    priors[["D"]][["sig_ddelta"]] <- 
    priors[["E"]][["sig_ddelta"]] <- sig_ddelta
```

## Scenario-dependent priors

For the time being, the prior mean of $\mu_T$ is based on the historical average of vote shares

```{r}
scenarios <- load_scenarios()
```

### $m_{\mu_T}$

Load fundamental forecast
```{r}
df_fcast <- readRDS(here::here("fundamental_forecast", "fundamental_forecast.rds"))
```

Loop over scenarios, convert to log ratio scale and store in list

```{r}
for (scen in scenarios) {
    df_fcast %>% 
    inner_join(
        load_dataland_states_regions(), 
        by = join_by(province == state)) %>%
    filter(scenario == scen) %>%
    select(-scenario) %>%
    mutate(party = toupper(party)) %>%
    group_by(province) %>%
    mutate(vote_share_lr = additive_log_ratio(vote_share)) %>% 
    filter(vote_share_lr != 0) %>% 
    arrange(region, province) %>%
    tidyr::unite(
        name, 
        province, 
        party, 
        sep = "_") -> df_m_mmu_T
    
    # check calc
    stopifnot(all(df_m_mmu_T$name == names_mmu_T))

    # store in list
    priors[[scen]][["m_mmu_T"]] <- df_m_mmu_T$vote_share_lr
    names(priors[[scen]][["m_mmu_T"]]) <- names_mmu_T
    rm(df_m_mmu_T)
}
```

### $V_{\mu_T}$

The prior variance can across scenarios to reflect how far advanced the campaign is. 

![](./../plots/available_polls_over_time.png)

In addition, it can also be set to a smaller value - placing greater weight on the fundamental forecast - in those states where within a given scenario fewer or no polls are available

![](./../plots/available_polls_by_geography.png)

For the time being, however, I set a relatively uninformative prior that is the same in all scenarios and states

```{r}
V_mmu_T <- diag(rep(1, sum(n_parties_by_state-1)))
dimnames(V_mmu_T) <- list(names_mmu_T, names_mmu_T)
```

Store in list
```{r}
priors[["A"]][["V_mmu_T"]] <- 
    priors[["B"]][["V_mmu_T"]] <- 
    priors[["C"]][["V_mmu_T"]] <- 
    priors[["D"]][["V_mmu_T"]] <- 
    priors[["E"]][["V_mmu_T"]] <- V_mmu_T
```

## Export


```{r}
saveRDS(priors, file = here::here("priors", "priors.Rds"))
```